{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darinkist/Medium-Article-Transparent-Question-Answering-Bot/blob/main/CodeForArticleYouTubeExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588da5df",
      "metadata": {
        "id": "588da5df"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain import OpenAI\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain import PromptTemplate\n",
        "import faiss\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-KEY>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca1b9ad",
      "metadata": {
        "id": "fca1b9ad"
      },
      "outputs": [],
      "source": [
        "# For Debugging - In case you are interested in what and how many prompts are sent to openAI\n",
        "# promptlayer account needed\n",
        "# import promptlayer\n",
        "# from promptlayer.langchain.llms import OpenAI\n",
        "# promptlayer.api_key = \"<YOUR-KEY>\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9e4827",
      "metadata": {
        "id": "7c9e4827"
      },
      "source": [
        "# Youtube\n",
        "## Option 1: Youtube transcripts without timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a14e4d",
      "metadata": {
        "id": "d7a14e4d"
      },
      "outputs": [],
      "source": [
        "yt_ids = [\n",
        "    \"OtD8wVaFm6E\",  # XGBoost Part 1 (of 4): Regression\n",
        "    \"8b1JEDvenQU\",  # XGBoost Part 2 (of 4): Classification\n",
        "    \"ZVFeW798-2I\",  # XGBoost Part 3 (of 4): Mathematical Details\n",
        "    \"oRrKeUCEbq8\",  # XGBoost Part 4 (of 4): Crazy Cool Optimizations\n",
        "]\n",
        "\n",
        "yt_docs = []\n",
        "\n",
        "for yt_id in tqdm(yt_ids, desc=\"Retrieving transcripts\"):\n",
        "    splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=150, separator=\" \")\n",
        "    yt_loader = YoutubeLoader(yt_id, add_video_info=True)\n",
        "    yt_docs.extend(yt_loader.load_and_split(splitter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054393ca",
      "metadata": {
        "id": "054393ca"
      },
      "outputs": [],
      "source": [
        "# Manipulate / extend source attribute\n",
        "for doc in yt_docs:\n",
        "    doc.metadata[\"source\"] = (\n",
        "        doc.metadata[\"title\"]\n",
        "        + \" [\"\n",
        "        + doc.metadata[\"author\"]\n",
        "        + \"] \"\n",
        "        + \"https://youtu.be/\"\n",
        "        + doc.metadata[\"source\"]\n",
        "    )\n",
        "\n",
        "# Vector store\n",
        "yt_store = FAISS.from_documents(yt_docs, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4949c499",
      "metadata": {
        "id": "4949c499"
      },
      "source": [
        "## Option 2: Youtube transcripts with timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392a2c94",
      "metadata": {
        "id": "392a2c94"
      },
      "outputs": [],
      "source": [
        "# Create transcript df\n",
        "def create_transcript_df(yt_transcript: list, yt_id: str):\n",
        "    return (\n",
        "        pd.DataFrame(yt_transcript)\n",
        "        .assign(start_dt=lambda x: pd.to_datetime(x[\"start\"], unit=\"s\"))\n",
        "        .set_index(\"start_dt\")\n",
        "        .resample(\"3min\")\n",
        "        .agg({\"text\": \" \".join})\n",
        "        .reset_index()\n",
        "        .assign(start_dt=lambda x: x[\"start_dt\"].dt.minute * 60)\n",
        "        .assign(\n",
        "            source=lambda x: \"https://youtu.be/\"\n",
        "            + yt_id\n",
        "            + \"&t=\"\n",
        "            + x[\"start_dt\"].astype(\"str\")\n",
        "        )\n",
        "        .drop(columns=[\"start_dt\"])\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47af52a",
      "metadata": {
        "id": "f47af52a"
      },
      "outputs": [],
      "source": [
        "yt_ids = [\n",
        "    \"OtD8wVaFm6E\",  # XGBoost Part 1 (of 4): Regression\n",
        "    \"8b1JEDvenQU\",  # XGBoost Part 2 (of 4): Classification\n",
        "    \"ZVFeW798-2I\",  # XGBoost Part 3 (of 4): Mathematical Details\n",
        "    \"oRrKeUCEbq8\",  # XGBoost Part 4 (of 4): Crazy Cool Optimizations\n",
        "]\n",
        "transcript_dfs = []\n",
        "for yt_id in tqdm(yt_ids, desc=\"Fetching transcription\"):\n",
        "    yt_transcript = YouTubeTranscriptApi.get_transcript(yt_id)\n",
        "    transcript_dfs.append(create_transcript_df(yt_transcript, yt_id))\n",
        "\n",
        "transcripts_df = pd.concat(transcript_dfs).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb66fb4",
      "metadata": {
        "id": "7bb66fb4"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(separator=\" \", chunk_size=1200, chunk_overlap=150)\n",
        "\n",
        "yt_docs, yt_meta = [], []\n",
        "\n",
        "for index, row in tqdm(transcripts_df.iterrows(), total=len(transcripts_df)):\n",
        "    splits = text_splitter.split_text(row[\"text\"])\n",
        "    yt_docs.extend(splits)\n",
        "    yt_meta.extend([{\"source\": row[\"source\"]}] * len(splits))\n",
        "    print(f\"Split {row['source']} into {len(splits)} chunks\")\n",
        "\n",
        "yt_ts_store = FAISS.from_texts(yt_docs, OpenAIEmbeddings(), metadatas=yt_meta)\n",
        "\n",
        "assert len(yt_docs) == len(yt_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a5db138",
      "metadata": {
        "id": "0a5db138"
      },
      "outputs": [],
      "source": [
        "yt_ts_store = FAISS.from_texts(yt_docs, OpenAIEmbeddings(), metadatas=yt_meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecac4b79",
      "metadata": {
        "id": "ecac4b79"
      },
      "source": [
        "# Question Answering Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f844f915",
      "metadata": {
        "id": "f844f915"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"question\",\n",
        "    output_key=\"answer\",\n",
        "    return_messages=True,\n",
        ")\n",
        "\n",
        "template = \"\"\"You are a chatbot having a conversation with a human.\n",
        "    Given the following extracted parts of a long document and a question,\n",
        "    create a final answer.\n",
        "    {context}\n",
        "    {chat_history}\n",
        "    Human: {question}\n",
        "    Chatbot:\"\"\"\n",
        "\n",
        "question_prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"question\", \"context\"], template=template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701d3653",
      "metadata": {
        "id": "701d3653"
      },
      "outputs": [],
      "source": [
        "# Do now the transparent question answering\n",
        "yt_ts_chain = RetrievalQAWithSourcesChain.from_llm(\n",
        "    llm=OpenAI(temperature=0.0),\n",
        "    retriever=yt_ts_store.as_retriever(k=4),\n",
        "    memory=memory,\n",
        "    question_prompt=question_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1101d85",
      "metadata": {
        "id": "a1101d85"
      },
      "outputs": [],
      "source": [
        "# Use here either yt_ts_store or ys_store depending if you like to use source with or without timestamps\n",
        "\n",
        "result = yt_ts_chain(\n",
        "    {\n",
        "        \"question\": \"What is the difference in building a tree for a regression case compared to a classification case?\"\n",
        "    },\n",
        "    return_only_outputs=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064296c6",
      "metadata": {
        "id": "064296c6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "289px",
        "width": "196px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}